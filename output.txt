nightmare.c:	clReleaseMemObject(net->delta_gpu);
nightmare.c:		clReleaseMemObject(net.delta_gpu);
gemm.c:	clReleaseMemObject(A_gpu);
gemm.c:	clReleaseMemObject(B_gpu);
gemm.c:	clReleaseMemObject(C_gpu);
gemm.c:	clReleaseMemObject(a_cl);
gemm.c:	clReleaseMemObject(b_cl);
gemm.c:	clReleaseMemObject(c_cl);
gemm.c:    clReleaseMemObject(a_cl);
gemm.c:    clReleaseMemObject(b_cl);
gemm.c:    clReleaseMemObject(c_cl);
region_layer.c:	clReleaseMemObject(l->delta_gpu);
region_layer.c:	clReleaseMemObject(l->output_gpu);
crop_layer.c:	clReleaseMemObject(l->output_gpu);
normalization_layer.c:	clReleaseMemObject(layer->output_gpu);
normalization_layer.c:	clReleaseMemObject(layer->delta_gpu);
normalization_layer.c:	clReleaseMemObject(layer->squared_gpu);
normalization_layer.c:	clReleaseMemObject(layer->norms_gpu);
grep: input file ‘output.txt’ is also the output
layer.c:        if(l.rand_gpu)             clReleaseMemObject(l.rand_gpu);
layer.c:    if(l.indexes_gpu)           clReleaseMemObject((float *)l.indexes_gpu);
layer.c:    if(l.z_gpu)                   clReleaseMemObject(l.z_gpu);
layer.c:    if(l.r_gpu)                   clReleaseMemObject(l.r_gpu);
layer.c:    if(l.h_gpu)                   clReleaseMemObject(l.h_gpu);
layer.c:    if(l.m_gpu)                   clReleaseMemObject(l.m_gpu);
layer.c:    if(l.v_gpu)                   clReleaseMemObject(l.v_gpu);
layer.c:    if(l.prev_state_gpu)          clReleaseMemObject(l.prev_state_gpu);
layer.c:    if(l.forgot_state_gpu)        clReleaseMemObject(l.forgot_state_gpu);
layer.c:    if(l.forgot_delta_gpu)        clReleaseMemObject(l.forgot_delta_gpu);
layer.c:    if(l.state_gpu)               clReleaseMemObject(l.state_gpu);
layer.c:    if(l.state_delta_gpu)         clReleaseMemObject(l.state_delta_gpu);
layer.c:    if(l.gate_gpu)                clReleaseMemObject(l.gate_gpu);
layer.c:    if(l.gate_delta_gpu)          clReleaseMemObject(l.gate_delta_gpu);
layer.c:    if(l.save_gpu)                clReleaseMemObject(l.save_gpu);
layer.c:    if(l.save_delta_gpu)          clReleaseMemObject(l.save_delta_gpu);
layer.c:    if(l.concat_gpu)              clReleaseMemObject(l.concat_gpu);
layer.c:    if(l.concat_delta_gpu)        clReleaseMemObject(l.concat_delta_gpu);
layer.c:    if(l.binary_input_gpu)        clReleaseMemObject(l.binary_input_gpu);
layer.c:    if(l.binary_weights_gpu)      clReleaseMemObject(l.binary_weights_gpu);
layer.c:    if(l.mean_gpu)                clReleaseMemObject(l.mean_gpu);
layer.c:    if(l.variance_gpu)            clReleaseMemObject(l.variance_gpu);
layer.c:    if(l.rolling_mean_gpu)        clReleaseMemObject(l.rolling_mean_gpu);
layer.c:    if(l.rolling_variance_gpu)    clReleaseMemObject(l.rolling_variance_gpu);
layer.c:    if(l.variance_delta_gpu)      clReleaseMemObject(l.variance_delta_gpu);
layer.c:    if(l.mean_delta_gpu)          clReleaseMemObject(l.mean_delta_gpu);
layer.c:    if(l.x_gpu)                   clReleaseMemObject(l.x_gpu);
layer.c:    if(l.x_norm_gpu)              clReleaseMemObject(l.x_norm_gpu);
layer.c:    if(l.weights_gpu)             clReleaseMemObject(l.weights_gpu);
layer.c:    if(l.weight_updates_gpu)      clReleaseMemObject(l.weight_updates_gpu);
layer.c:    if(l.biases_gpu)              clReleaseMemObject(l.biases_gpu);
layer.c:    if(l.bias_updates_gpu)        clReleaseMemObject(l.bias_updates_gpu);
layer.c:    if(l.scales_gpu)              clReleaseMemObject(l.scales_gpu);
layer.c:    if(l.scale_updates_gpu)       clReleaseMemObject(l.scale_updates_gpu);
layer.c:    if(l.output_gpu)              clReleaseMemObject(l.output_gpu);
layer.c:    if(l.delta_gpu)               clReleaseMemObject(l.delta_gpu);
layer.c:    if(l.rand_gpu)                clReleaseMemObject(l.rand_gpu);
layer.c:    if(l.squared_gpu)             clReleaseMemObject(l.squared_gpu);
layer.c:    if(l.norms_gpu)               clReleaseMemObject(l.norms_gpu);
network.c:	clReleaseMemObject(net->workspace);
network.c:		clReleaseMemObject(net->input_gpu);
network.c:		clReleaseMemObject(net->truth_gpu);
network.c:    if(net.input_gpu) clReleaseMemObject(net.input_gpu);//cuda_free(net.input_gpu);
network.c:    if(net.truth_gpu) clReleaseMemObject(net.truth_gpu);//cuda_free(net.truth_gpu);
route_layer.c:	clReleaseMemObject(l->output_gpu);
route_layer.c:	clReleaseMemObject(l->delta_gpu);
reorg_layer.c:	clReleaseMemObject(l->output_gpu);
reorg_layer.c:	clReleaseMemObject(l->delta_gpu);
convolutional_layer.c:	clReleaseMemObject(l->delta_gpu);
convolutional_layer.c:	clReleaseMemObject(l->output_gpu);
convolutional_layer.c:		clReleaseMemObject(l->x_gpu);
convolutional_layer.c:		clReleaseMemObject(l->x_norm_gpu);
maxpool_layer.c:	clReleaseMemObject((float *)l->indexes_gpu);
maxpool_layer.c:	clReleaseMemObject(l->output_gpu);
maxpool_layer.c:	clReleaseMemObject(l->delta_gpu);
cost_layer.c:	clReleaseMemObject(l->delta_gpu);
cost_layer.c:	clReleaseMemObject(l->output_gpu);
dropout_layer.c:	clReleaseMemObject(l->rand_gpu);
deconvolutional_layer.c:	clReleaseMemObject(l->delta_gpu);
deconvolutional_layer.c:	clReleaseMemObject(l->output_gpu);
deconvolutional_layer.c:		clReleaseMemObject(l->x_gpu);
deconvolutional_layer.c:		clReleaseMemObject(l->x_norm_gpu);
